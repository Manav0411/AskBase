# ================================
# Application Configuration
# ================================
APP_NAME=AskBase
ENV=dev

# ================================
# Security & Authentication
# ================================
# Generate a secure random string for JWT_SECRET (at least 32 characters)
# You can use: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET=change-this-to-a-secure-random-string
JWT_ALGORITHM=HS256

# ================================
# Database Configuration
# ================================
# SQLite (default for development)
DATABASE_URL=sqlite:///./askbase.db

# PostgreSQL (recommended for production)
# DATABASE_URL=postgresql://username:password@localhost:5432/askbase

# MySQL
# DATABASE_URL=mysql+pymysql://username:password@localhost:3306/askbase

# ================================
# Groq API Configuration
# ================================
# Get your API key from: https://console.groq.com/
GROQ_API_KEY=your-groq-api-key-here

# ================================
# HuggingFace Configuration (Optional)
# ================================
# Only needed if using HuggingFace inference API
HF_API_KEY=
HF_MODEL=

# ================================
# CORS Configuration
# ================================
# Comma-separated list of allowed origins
# Development
CORS_ORIGINS=http://localhost:5173,http://localhost:5174

# Production example
# CORS_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# ================================
# Pagination Configuration
# ================================
DEFAULT_PAGE_SIZE=20
MAX_PAGE_SIZE=100

# ================================
# File Upload Configuration
# ================================
# Maximum file size in megabytes
MAX_FILE_SIZE_MB=10

# ================================
# Text Chunking Configuration
# ================================
# Size of each text chunk for vector embedding
CHUNK_SIZE=1200

# Number of characters to overlap between chunks
CHUNK_OVERLAP=200

# ================================
# Embedding Model Configuration
# ================================
# HuggingFace embedding model to use
# Options:
# - BAAI/bge-small-en-v1.5 (default, fast, good quality)
# - BAAI/bge-base-en-v1.5 (larger, better quality)
# - sentence-transformers/all-MiniLM-L6-v2 (lightweight)
# - sentence-transformers/all-mpnet-base-v2 (high quality)
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5

# ================================
# Retrieval Configuration (RAG)
# ================================
# Number of chunks to retrieve for each query
RETRIEVAL_K=6

# Use Maximum Marginal Relevance for diversity
USE_MMR=true

# MMR diversity score (0.0 = no diversity, 1.0 = maximum diversity)
MMR_DIVERSITY=0.3

# Number of documents to fetch before MMR re-ranking
MMR_FETCH_K=20

# ================================
# LLM Configuration
# ================================
# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.3

# Maximum number of tokens in LLM response
LLM_MAX_TOKENS=1500
